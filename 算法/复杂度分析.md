# 复杂度分析

复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系。

## 1. 大O表示法

`大O表示法` 是对复杂度的一种表示方法。描述的是算法执行效率和数据规模之间的关系，并不代表具体的复杂度。

$T(n) = O(f(n))$

**大O表示法中，公式的低阶、常量、系数三部分不影响增长趋势，所有均可忽略。**

## 2. 时间复杂度分析

时间复杂度，全称 `渐进时间复杂度`。表示算法的执行时间与数据规模之间的增长关系。

### 2.1 时间复杂度分析的三个实用方法

1. 只关注循环次数最多的一段代码

2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

eg：如果 $T1(n)=O(f(n))$, $T2(n)=O(g(n))$; 那么 $T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n)))$

3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

eg： 如果 $T1(n)=O(f(n))$，$T2(n)=O(g(n))$；那么 $T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n))$.

### 2.2 几种常见时间复杂度

| 复杂度量级 | 大O表示法 |
| --- | --- |
| 常量阶 | O(1) |
| 对数阶 | O(logn) |
| 线性阶 | O(n) |
| 线性对数阶 | O(nlogn) |
| 平方阶 | O(n^2) |
| 立方阶 | O(n^3) |
| k次方阶 | O(n^k) |
| 指数阶 | O(2^n) |
| 阶乘阶 | O(n!) |

对上述时间复杂度进行分类，可分为多项式量级和非多项式量级。其中非多项式量级只有 O(2^n) 和 O(n!)

## 3. 空间复杂度分析

空间复杂度，全称 `渐进空间复杂度`。表示算法的存储空间与数据规模之间的增长关系。

## 4. 常见时间复杂度关系图

![alt 常见时间复杂度关系图](./Resources/pic1.webp)

## 5. 特殊情况时间复杂度分析

```swift
func find(array: [Int], target: Int) -> Int {
    for (idx, item) in array.enumerated() {
        if item == target {
            return idx
        }
    }
    return -1
}
```

### 5.1 最好情况时间复杂度

最好情况时间复杂度，就是在最理想的情况下，执行这段代码的时间复杂度。

针对上述代码，在最理想的情况下，数组的第一个元素就是我们要查找的目标元素，此时时间复杂度为 $O(1)$，即为这段代码的最好情况时间复杂度。

### 5.2 最坏情况时间复杂度

最坏情况时间复杂度，就是在最糟糕的情况下，执行这段代码的时间复杂度。

针对上述代码，在最糟糕的情况下，需要遍历完整个数组才能找到目标元素，此时时间复杂度为 $O(n)$，即为这段代码的最坏情况时间复杂度。

### 5.3 平均情况时间复杂度

上述代码中，要查找的数在数组中的位置有 `n+1` 种情况：在数组的 `0~n-1` 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即:

$$(1+2+...+n+n)/(n+1)=n(n+3)/2(n+1)$$

简化之后得到的平均时间复杂度就是 $O(n)$

上述分析的结论是正确的，但是分析过程有点问题。我们刚讲的这 `n+1` 种情况，出现的概率不一样。上述分析过程中，未考虑各种情况出现的概率。

要查找的数，要么在数组内，要么不在数组内，这两种情况对应的概率统计起来太麻烦，这里为了方便，假设在数组中和不在数组中的概率均为 `1/2`。另外，要查找的数据出现在 `0~n-1` 这 n 个位置上的概率也是一样的，都是 `1/n`。所以，根据概率乘法法则，要查找的数据出现在 `0~n-1` 中任意位置的概率均为 `1/2n`

再考虑每种情况遍历元素的个数，得到下面公式：

$$1*1/(2n)+2*1/(2n)+3*1/(2n)+...+n*1/(2n)+n*1/2=(3n+1)/4$$

这个值就是概率论中的**加权平均数**，也叫做**期望值**，所以平均时间复杂度的全称应该叫做**加权平均时间复杂度**或**期望时间复杂度**。

引入概率之后，前面那段代码的加权平均值为 `(3n+1)/4`，使用大O表示法简化之后，仍为 `O(n)`。

### 5.4 均摊时间复杂度

```swift
// n为指定的数组长度
var array = [Int]()
var count = 0

func insert(val: Int) {
    if count == n {
        var sum = 0
        for item in array {
            sum += item
        }
        array[0] = sum
        count = 1
    }
    
    array[count] = val
    count += 1
}
```

分析上述代码，可以发现，在大部分情况下，代码的时间复杂度为 $O(1)$。只有在个别情况下，复杂度才比较高，为 $O(n)$。并且这两种情况的出现是有交替规律的，一般都是一个 $O(n)$ 插入之后，紧跟着 `n-1` 个 $O(1)$ 的插入操作。

针对这种特殊情况，我们引入一个更加简单的分析方法：**摊还分析法**，通过摊还分析得到的时间复杂度我们起了一个名字，叫做**均摊时间复杂度**。

每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。

> 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。
